{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストを使った特徴抽出\n",
    "CountVectorizerを使ったベクトルによる抽出方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('allice.txt', <http.client.HTTPMessage at 0x215fd71c9e8>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", \"allice.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, ‘and what is the use of a book,’ thought Alice ‘without pictures or\n",
      "conversations?’\n",
      "\n",
      "So she was considering in her own mind (as well as she could, for the\n",
      "hot day made her feel very sleepy and stupid), whether the pleasure\n",
      "of making a daisy-chain would be worth the trouble of getting up and\n",
      "picking the daisies, when suddenly a White Rabbit with pink eyes ran\n",
      "close by her.\n",
      "\n",
      "There was nothing so VERY remarkable in that; nor did Alice \n"
     ]
    }
   ],
   "source": [
    "with open('allice.txt', 'r', encoding='UTF-8') as f:\n",
    "    print(f.read()[710:1400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_vec = CountVectorizer(input='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='filename',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_vec.fit(['allice.txt']) # 単語をカウントして、ベクトル化している？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['along',\n",
       " 'aloud',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alteration',\n",
       " 'altered',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'ambition',\n",
       " 'among',\n",
       " 'an',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'anger',\n",
       " 'angrily',\n",
       " 'angry',\n",
       " 'animal']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_vec.get_feature_names()[100:120] # 単語が抽出されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3019"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_vec.get_feature_names()) # Alliceに含まれる単語数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "allice_vec = txt_vec.transform(['allice.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3019)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allice_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "allice_vec = allice_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,   5,   3,   4,   1,   1,   1,   1,   5,  13,  16,   1,  12,\n",
       "        61,   1, 940,   2,   9,   5,   2], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allice_vec[0, 100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "along 6\n",
      "aloud 5\n",
      "already 3\n",
      "also 4\n",
      "alteration 1\n",
      "altered 1\n",
      "alternate 1\n",
      "alternately 1\n",
      "altogether 5\n",
      "always 13\n",
      "am 16\n",
      "ambition 1\n",
      "among 12\n",
      "an 61\n",
      "ancient 1\n",
      "and 940\n",
      "anger 2\n",
      "angrily 9\n",
      "angry 5\n",
      "animal 2\n"
     ]
    }
   ],
   "source": [
    "for word, count in zip(txt_vec.get_feature_names()[100:120], allice_vec[0, 100:120]):\n",
    "    print(word, count)\n",
    "# 単語、出現回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
